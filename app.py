import streamlit as st
from langchain_openai import ChatOpenAI
from langchain.memory import StreamlitChatMessageHistory, ConversationBufferMemory
from langchain.chains import ConversationChain
from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate

st.title("ğŸ’¬AIãƒãƒ£ãƒƒãƒˆ")

# --- APIã‚­ãƒ¼å…¥åŠ›æ¬„ ---
api_key = st.text_input(
    "OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆå…¥åŠ›å¾Œã€ã‚¨ãƒ³ã‚¿ãƒ¼ã§ã‚»ãƒƒãƒˆï¼‰",
    type="password",
    value=st.session_state.get("api_key", ""),
)
if api_key:
    st.session_state["api_key"] = api_key

if "api_key" not in st.session_state or not st.session_state["api_key"]:
    st.info("OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# --- ãƒãƒ£ãƒƒãƒˆå±¥æ­´ç”¨ãƒ¡ãƒ¢ãƒª ---
msgs = StreamlitChatMessageHistory()
memory = ConversationBufferMemory(
    chat_memory=msgs,
    return_messages=True,
    memory_key="history",
)

# --- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æŒ‡å®šï¼ˆhistoryåŸ‹ã‚è¾¼ã¿ã¯humanã®å‰ã«ï¼‰ ---
prompt = ChatPromptTemplate.from_messages([
    ("system", "ã‚ãªãŸã¯è¦ªåˆ‡ãªAIãƒãƒ£ãƒƒãƒˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚å¿…ãšæ—¥æœ¬èªã§ç°¡æ½”ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚"),
    ("human", "{history}\n{input}")
])

# --- LangChain LLM ---
llm = ChatOpenAI(
    openai_api_key=st.session_state["api_key"],
    model="gpt-3.5-turbo",
    temperature=0.7,
)

chain = ConversationChain(
    llm=llm,
    memory=memory,
    prompt=prompt,
    verbose=False,
)

# --- ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¡¨ç¤º ---
for msg in msgs.messages:
    st.chat_message(msg.type).write(msg.content)

# --- å…¥åŠ› ---
user_input = st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›â€¦")

if user_input:
    st.chat_message("user").write(user_input)
    output = chain.run(user_input)
    st.chat_message("assistant").write(output)
